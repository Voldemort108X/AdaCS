{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Code', 'Dataset', 'Models', 'Webpage']\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvoldemort108x\u001b[0m (\u001b[33mvoldemort_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/d/XiaoranZhang/Projects_organized/Code/AdaCS/wandb/run-20240312_092545-8enobxw4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvxm_ACDC_AdaCS\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/voldemort_team/AdaCS\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/voldemort_team/AdaCS/runs/8enobxw4\u001b[0m\n",
      "/home/xiaoranzhang/anaconda3/envs/AdaCS_env/lib/python3.6/site-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "Epoch 1/300 - 0.2538 sec/step - motion loss: 8.8447e-03  (4.4216e-03, 4.4229e-03, 1.1266e-07) - GPU Memory Allocated: 4.45 MB, Reserved: 92.00 MB\n",
      "Epoch 2/300 - 0.2175 sec/step - scoring loss: 9.4377e-03  (4.9543e-03, 4.4777e-03, 5.6760e-06) - GPU Memory Allocated: 6.22 MB, Reserved: 248.00 MB\n",
      "Epoch 3/300 - 0.2485 sec/step - motion loss: 6.3330e-03  (3.2403e-03, 3.0913e-03, 1.3844e-06) - GPU Memory Allocated: 6.22 MB, Reserved: 248.00 MB\n",
      "Epoch 3/300 - 0.2485 sec/step - scoring loss: 8.0458e-03  (6.3313e-03, 1.5703e-03, 1.4413e-04) - GPU Memory Allocated: 6.22 MB, Reserved: 248.00 MB\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_vxm.py\", line 432, in <module>\n",
      "    scoring_loss.backward()\n",
      "  File \"/home/xiaoranzhang/anaconda3/envs/AdaCS_env/lib/python3.6/site-packages/torch/_tensor.py\", line 255, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/xiaoranzhang/anaconda3/envs/AdaCS_env/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 149, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python train_vxm.py --dataset 'ACDC'  --bidir --model-dir '../../Models/AdaCS/ACDC/vxm_ACDC_AdaCS' --motion-loss-type 'wmse' --scoring-loss-type 'scoringwmse' --batch-size 8 --accumulation_steps 2 --epochs 300  --warm_start --wandb-name 'vxm_ACDC_AdaCS' --alpha 0.02 --beta 1.5  --warm_start_epoch 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiaoranzhang/anaconda3/envs/AdaCS_env/lib/python3.6/site-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"test_vxm.py\", line 84, in <module>\n",
      "    ES_myo_pred = warp_layer(input_ED_myo, dvf.to(device))\n",
      "  File \"/home/xiaoranzhang/anaconda3/envs/AdaCS_env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/mnt/d/XiaoranZhang/Projects_organized/Code/AdaCS/models/voxelmorph/torch/layers.py\", line 53, in forward\n",
      "    new_locs = new_locs[..., [1, 0]]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python test_vxm.py --dataset 'ACDC' --test-dir '../../Dataset/ACDC/test/' --result-dir '../../Results/AdaCS/ACDC/vxm_AdaCS/' --model-motion '../../Models/AdaCS/ACDC/vxm_ACDC_AdaCS/motion_0000.pt' --model-scoring '../../Models/AdaCS/ACDC/vxm_ACDC_AdaCS/scoring_0000.pt' --inshape 128 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdaCS_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
